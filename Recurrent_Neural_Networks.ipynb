{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1xtk0GlgjVNWZsHwG8-vcmgWgj3my3lv4",
      "authorship_tag": "ABX9TyMC+Fo3J9EtTggZQ8Zr4X+N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zelalemamera-stonybrook/projects-sandbox/blob/main/Recurrent_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t8cqCkctcC7n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/charles_dickens_christmas_carol.txt', 'r') as f:\n",
        "  scroodge_book = f.read()"
      ],
      "metadata": {
        "id": "egNJtNmlO0e7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_sentences(sentence_list):\n",
        "  '''\n",
        "  Add SOS - start of sentence and EOS end of sentence markers.\n",
        "  Add EOSq for end of sentence question\n",
        "  replace ; : with EOS\n",
        "  replace ! with ,\n",
        "  remove - i.e. treat every compound word as one unit\n",
        "  remove all numbers\n",
        "  remove \\\n",
        "  remove \"\n",
        "  '''\n",
        "  cleaned_sentence_list = []\n",
        "  for sentence in sentence_list:\n",
        "    filtered = re.sub(r\"[;:,]\", r\"\", sentence)\n",
        "    filtered = re.sub(r\"\\.\", r\" eos\", filtered)\n",
        "    filtered = re.sub(r\"\\?\", r\" eosq\", filtered)\n",
        "    filtered = re.sub(r\"!\", r\"\", filtered)\n",
        "    filtered = re.sub(r\"-\", r\"\", filtered)\n",
        "    filtered = re.sub(r\"\\d\", r\"\", filtered)\n",
        "    filtered = re.sub(r\"\\\\\", r\"\", filtered)\n",
        "    filtered = re.sub(r\"\\\"\", r\"\", filtered)\n",
        "    filtered = re.sub(r\"\\s+\", r\" \", filtered)\n",
        "    filtered = filtered.lower()\n",
        "    cleaned_sentence_list.append(f\"sos {filtered}\")\n",
        "  return cleaned_sentence_list\n",
        "\n"
      ],
      "metadata": {
        "id": "8iXO0PcuHFu0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_book_and_tokenize_sentences(book):\n",
        "  '''\n",
        "  '''\n",
        "  list_of_undesirables = [\"STAVE I:  MARLEY'S GHOST\", \"STAVE II:  THE FIRST OF THE THREE SPIRITS\", \"STAVE III:  THE SECOND OF THE THREE SPIRITS\",\n",
        "                   \"A CHRISTMAS CAROL\", \"Stave IV:  The Last of the Spirits\", \"Stave V:  The End of It\"]\n",
        "  for string in list_of_undesirables:\n",
        "    book = re.sub(string, r\"\", book)\n",
        "  book = re.sub(\"\\n\", r\" \", book)\n",
        "  sentence_list = [\". marley was dead.\"]\n",
        "  appendage = re.findall(r\"\\..*?\\.\", book)\n",
        "  for appendend in appendage:\n",
        "    sentence_list.append(appendend)\n",
        "  for i, sentence in enumerate(sentence_list):\n",
        "    sentence_list[i] = sentence[1:].strip()\n",
        "  cleaned_sentence_list = clean_sentences(sentence_list)\n",
        "  return cleaned_sentence_list\n",
        ""
      ],
      "metadata": {
        "id": "y8d3UOKLTxSO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_list = clean_book_and_tokenize_sentences(scroodge_book)"
      ],
      "metadata": {
        "id": "Ohx067ANXce-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = [1,2,3, 4, 5, 6]\n",
        "b = [2,3,4,5,6]\n",
        "c = [3,4,5,6]\n",
        "d = zip(a,b,c)\n",
        "for i in d:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-AcdAsWjaSK",
        "outputId": "9d91338f-6086-499f-953e-96af89b2df59"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 2, 3)\n",
            "(2, 3, 4)\n",
            "(3, 4, 5)\n",
            "(4, 5, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_list[-20:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXS-6V4dYV7C",
        "outputId": "b20bdbba-76a3-4c04-cd2e-eb51647c2091"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sos your uncle scrooge eos',\n",
              " \"sos will you let me in fred eosq let him in it is a mercy he didn't shake his arm off eos\",\n",
              " 'sos nothing could be heartier eos',\n",
              " 'sos so did topper when he came eos',\n",
              " 'sos so did every one when they came eos',\n",
              " 'sos oh he was early there eos',\n",
              " 'sos and he did it yes he did the clock struck nine eos',\n",
              " 'sos a quarter past eos',\n",
              " 'sos he was full eighteen minutes and a half behind his time eos',\n",
              " 'sos his hat was off before he opened the door his comforter too eos',\n",
              " 'sos hallo growled scrooge in his accustomed voice as near as he could feign it eos',\n",
              " 'sos i am behind my time eos',\n",
              " 'sos yes eos',\n",
              " 'sos step this way sir if you please eos',\n",
              " 'sos it shall not be repeated eos',\n",
              " \"sos  now i'll tell you what my friend said scrooge i am not going to stand this sort of thing any longer eos\",\n",
              " 'sos he had a momentary idea of knocking scrooge down with it holding him and calling to the people in the court for help and a straitwaistcoat eos',\n",
              " \"sos a merrier christmas bob my good fellow than i have given you for many a year i'll raise your salary and endeavour to assist your struggling family and we will discuss your affairs this very afternoon over a christmas bowl of smoking bishop bob make up the fires and buy another coalscuttle before you dot another i bob cratchit scrooge was better than his word eos\",\n",
              " 'sos he became as good a friend as good a master and as good a man as the good old city knew or any other good old city town or borough in the good old world eos',\n",
              " 'sos his own heart laughed and that was quite enough for him eos']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_one_hot_mapping(sentence_list):\n",
        "  '''\n",
        "  '''\n",
        "  words_to_int = {}\n",
        "  int_to_words = {}\n",
        "  size = 0\n",
        "  for sentence in sentence_list:\n",
        "    words = re.split(r\"\\s\", sentence)\n",
        "    for word in words:\n",
        "      if word in words_to_int.keys():\n",
        "        continue\n",
        "      else:\n",
        "        words_to_int[word] = size\n",
        "        int_to_words[size] = word\n",
        "        size += 1\n",
        "  return (int_to_words, words_to_int)\n"
      ],
      "metadata": {
        "id": "n2YIJUvJdHMf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_to_num(sentence_list):\n",
        "  '''\n",
        "  '''\n",
        "  num_dict, word_dict = generate_one_hot_mapping(sentence_list)\n",
        "  translated_sequences = []\n",
        "  for sentence in sentence_list:\n",
        "    words = re.split(r\"\\s\", sentence)\n",
        "    sequence = []\n",
        "    for word in words:\n",
        "      try:\n",
        "        sequence.append(word_dict[word])\n",
        "      except Exception:\n",
        "        continue\n",
        "    translated_sequences.append(sequence)\n",
        "  return translated_sequences, num_dict, word_dict"
      ],
      "metadata": {
        "id": "4mekycLtlQDC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_training_data(sentence_list):\n",
        "  '''\n",
        "  '''\n",
        "  tensor_list = []\n",
        "  string_sequences, num_dict, word_dict = translate_to_num(sentence_list)\n",
        "  word_dimension = len(num_dict.keys())\n",
        "  for sentence in string_sequences:\n",
        "    if len(sentence) >= 7:\n",
        "      zipped = zip(sentence, sentence[1:], sentence[2:], sentence[3:], sentence[4:], sentence[5:], sentence[6:])\n",
        "      for tup in zipped:\n",
        "        if tup in tensor_list:\n",
        "          continue\n",
        "        tensor_list.append(tup)\n",
        "  matrix_list = []\n",
        "  for tup in tensor_list:\n",
        "    tensor = torch.zeros((7, word_dimension))\n",
        "    for i in range(len(tup)):\n",
        "      tensor[i,tup[i]] = 1\n",
        "    matrix_list.append(tensor)\n",
        "  return matrix_list, num_dict, word_dict"
      ],
      "metadata": {
        "id": "X1V1493MxWTh"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string_matrices, num_dict, word_dict = generate_training_data(sentence_list)"
      ],
      "metadata": {
        "id": "FZhxf2bIwHq2"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string_matrices[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8fl13F0tgL-",
        "outputId": "8bdd9fe0-4256-4461-abee-f17c06793bdb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
              " tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
              " tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
              " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
              " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]])]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_strings(string_matrices, num_dict):\n",
        "  '''\n",
        "  '''\n",
        "  string_list = []\n",
        "  for matrix in string_matrices:\n",
        "    word1 = num_dict[torch.argmax(matrix[0,:]).item()]\n",
        "    word2 = num_dict[torch.argmax(matrix[1,:]).item()]\n",
        "    word3 = num_dict[torch.argmax(matrix[2,:]).item()]\n",
        "    word4 = num_dict[torch.argmax(matrix[3:]).item()]\n",
        "    word5 = num_dict[torch.argmax(matrix[4:]).item()]\n",
        "    word6 = num_dict[torch.argmax(matrix[5:]).item()]\n",
        "    word7 = num_dict[torch.argmax(matrix[6:]).item()]\n",
        "    string_list.append((word1,word2,word3, word4, word5, word6, word7))\n",
        "  return string_list"
      ],
      "metadata": {
        "id": "1mFVLLCpGiLQ"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string_list = to_strings(string_matrices, num_dict)"
      ],
      "metadata": {
        "id": "6fZJeFlRHJtx"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string_list[:30]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjKO-iXrHg_3",
        "outputId": "2fd288a4-6ae0-4a10-bafa-23579c39ea55"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('sos', 'there', 'is', 'no', 'doubt', 'whatever', 'about'),\n",
              " ('there', 'is', 'no', 'doubt', 'whatever', 'about', 'that'),\n",
              " ('is', 'no', 'doubt', 'whatever', 'about', 'that', 'eos'),\n",
              " ('sos', 'scrooge', 'signed', 'it', 'and', \"scrooge's\", 'name'),\n",
              " ('scrooge', 'signed', 'it', 'and', \"scrooge's\", 'name', 'was'),\n",
              " ('signed', 'it', 'and', \"scrooge's\", 'name', 'was', 'good'),\n",
              " ('it', 'and', \"scrooge's\", 'name', 'was', 'good', 'upon'),\n",
              " ('and', \"scrooge's\", 'name', 'was', 'good', 'upon', \"'change\"),\n",
              " (\"scrooge's\", 'name', 'was', 'good', 'upon', \"'change\", 'for'),\n",
              " ('name', 'was', 'good', 'upon', \"'change\", 'for', 'anything'),\n",
              " ('was', 'good', 'upon', \"'change\", 'for', 'anything', 'he'),\n",
              " ('good', 'upon', \"'change\", 'for', 'anything', 'he', 'chose'),\n",
              " ('upon', \"'change\", 'for', 'anything', 'he', 'chose', 'to'),\n",
              " (\"'change\", 'for', 'anything', 'he', 'chose', 'to', 'put'),\n",
              " ('for', 'anything', 'he', 'chose', 'to', 'put', 'his'),\n",
              " ('anything', 'he', 'chose', 'to', 'put', 'his', 'hand'),\n",
              " ('he', 'chose', 'to', 'put', 'his', 'hand', 'to'),\n",
              " ('chose', 'to', 'put', 'his', 'hand', 'to', 'eos'),\n",
              " ('sos', 'mind', 'i', \"don't\", 'mean', 'to', 'say'),\n",
              " ('mind', 'i', \"don't\", 'mean', 'to', 'say', 'that'),\n",
              " ('i', \"don't\", 'mean', 'to', 'say', 'that', 'i'),\n",
              " (\"don't\", 'mean', 'to', 'say', 'that', 'i', 'know'),\n",
              " ('mean', 'to', 'say', 'that', 'i', 'know', 'of'),\n",
              " ('to', 'say', 'that', 'i', 'know', 'of', 'my'),\n",
              " ('say', 'that', 'i', 'know', 'of', 'my', 'own'),\n",
              " ('that', 'i', 'know', 'of', 'my', 'own', 'knowledge'),\n",
              " ('i', 'know', 'of', 'my', 'own', 'knowledge', 'what'),\n",
              " ('know', 'of', 'my', 'own', 'knowledge', 'what', 'there'),\n",
              " ('of', 'my', 'own', 'knowledge', 'what', 'there', 'is'),\n",
              " ('my', 'own', 'knowledge', 'what', 'there', 'is', 'particularly')]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super().__init__()\n",
        "    output_matrix = torch.rand((output_size, hidden_size), requires_grad=True)\n",
        "    self.output_layer = nn.Parameter(output_matrix, requires_grad=True)\n",
        "    self.output_layer_bias = nn.Parameter(torch.rand((output_size)), requires_grad=True)\n",
        "    self.loss = nn.CrossEntropyLoss()\n",
        "    self.output_size = output_size\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.hidden_layer = nn.RNNCell(input_size, hidden_size)\n",
        "\n",
        "  def forward(self, input_batch):\n",
        "    hidden_list = []\n",
        "    total_time = input_batch.shape[0]\n",
        "    size_of_batch = input_batch.shape[1]\n",
        "    h0 = torch.zeros((size_of_batch, self.hidden_size))\n",
        "    for time_step in input_batch:\n",
        "      h0 = self.hidden_layer(time_step, h0)\n",
        "      hidden_list.append(h0)\n",
        "    final_hidden = hidden_list[-1]\n",
        "    output = []\n",
        "    for tensor in final_hidden:\n",
        "      current = (self.output_layer @ tensor) + self.output_layer_bias\n",
        "      output.append(current)\n",
        "    output = torch.vstack(tuple(output))\n",
        "    return output\n",
        "\n"
      ],
      "metadata": {
        "id": "3z5bMnSNGOGO"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, string_matrices, epochs):\n",
        "  '''\n",
        "  '''\n",
        "  model.train()\n",
        "  optim = torch.optim.Adam(model.parameters())\n",
        "  batched = batch_matrices(string_matrices, 7)\n",
        "  for i, batch in enumerate(batched):\n",
        "    training = batch[:7]\n",
        "    target = batch[-1]\n",
        "    print(f\"batch: {i}\")\n",
        "    avg_loss = float('inf')\n",
        "    maximum_iterations = 1\n",
        "    last_improved = 0\n",
        "    accuracy = 0\n",
        "    while accuracy < 90 and maximum_iterations < epochs and last_improved < 4:\n",
        "      print(f\"epoch: {maximum_iterations}\")\n",
        "      optim.zero_grad()\n",
        "      output = model.forward(training)\n",
        "      loss = model.loss(output, target)\n",
        "      loss.backward()\n",
        "      optim.step()\n",
        "      avg_loss = loss.item()\n",
        "      maximum_iterations+=1\n",
        "      current_accuracy = model_accuracy(model, training, target)\n",
        "      print(f\"batch accuracy: {current_accuracy}\")\n",
        "      if current_accuracy <= accuracy:\n",
        "        last_improved+=1\n",
        "      accuracy = current_accuracy\n"
      ],
      "metadata": {
        "id": "EY8rv9T_JtOW"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_matrices(string_matrices, n):\n",
        "  '''\n",
        "  '''\n",
        "  N = 500\n",
        "  length = len(string_matrices)\n",
        "  batches = int(length / N)\n",
        "  remainder = length % N\n",
        "  batched_matrices = []\n",
        "  for i in range(batches):\n",
        "    batch = string_matrices[i * N: (i + 1) * N]\n",
        "    input_tensor = []\n",
        "    for t in range(n):\n",
        "      current_time = []\n",
        "      for matrix in batch:\n",
        "        current_time.append(matrix[t,:])\n",
        "      input_tensor.append(torch.vstack(tuple(current_time)))\n",
        "    input_tensor = torch.vstack(tuple(input_tensor))\n",
        "    input_tensor = torch.reshape(input_tensor, (n, N, -1))\n",
        "    batched_matrices.append(input_tensor)\n",
        "  remaining_batch = string_matrices[length - remainder: length]\n",
        "  remainder_tensor = []\n",
        "  for t in range(n):\n",
        "    current_time = []\n",
        "    for matrix in remaining_batch:\n",
        "      current_time.append(matrix[t,:])\n",
        "    current_time = torch.vstack(tuple(current_time))\n",
        "    remainder_tensor.append(current_time)\n",
        "  remainder_tensor = torch.vstack(tuple(remainder_tensor))\n",
        "  remainder_tensor = torch.reshape(remainder_tensor, (n, remainder, -1))\n",
        "  batched_matrices.append(remainder_tensor)\n",
        "  return batched_matrices\n"
      ],
      "metadata": {
        "id": "qwn2WmFuhBvC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_accuracy(model, input_data, target_data):\n",
        "  '''\n",
        "  '''\n",
        "  model.eval()\n",
        "  softmax = nn.Softmax(dim=1)\n",
        "  predictions = torch.argmax(softmax(model.forward(input_data)), dim=1)\n",
        "  target = torch.argmax(target_data, dim=1)\n",
        "  score = 100 * (torch.sum(torch.eq(predictions, target))).item() / len(target_data)\n",
        "  return score\n"
      ],
      "metadata": {
        "id": "hqFGBjLY8Xkz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(num_dict.keys())\n",
        "print(f\"vocab size: {vocab_size}\", f\"training_size: {len(string_matrices)}\")\n",
        "input_size = vocab_size\n",
        "hidden_size = 1000\n",
        "output_size = vocab_size\n",
        "total_params = hidden_size * input_size + hidden_size * hidden_size + output_size * hidden_size + hidden_size + hidden_size + output_size\n",
        "print(f\"total parameters: {total_params}\", f\"\\napproximate size: {float((total_params * 32) / float(10**9))} giga bytes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLL_YHhcRXot",
        "outputId": "7e9bd02b-7eef-4df3-c3cd-a0518c5ce67b"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size: 2917 training_size: 11462\n",
            "total parameters: 6838917 \n",
            "approximate size: 0.218845344 giga bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn = RNN(input_size, hidden_size, output_size)"
      ],
      "metadata": {
        "id": "G4D48BepL2ao"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(rnn, string_matrices, 15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhu27TaIT54x",
        "outputId": "13154a34-aa1a-4015-e5d4-432f11ea5b64"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch: 0\n",
            "epoch: 1\n",
            "batch accuracy: 10.2\n",
            "epoch: 2\n",
            "batch accuracy: 9.6\n",
            "epoch: 3\n",
            "batch accuracy: 36.2\n",
            "epoch: 4\n",
            "batch accuracy: 84.6\n",
            "epoch: 5\n",
            "batch accuracy: 94.8\n",
            "batch: 1\n",
            "epoch: 1\n",
            "batch accuracy: 50.0\n",
            "epoch: 2\n",
            "batch accuracy: 51.6\n",
            "epoch: 3\n",
            "batch accuracy: 52.6\n",
            "epoch: 4\n",
            "batch accuracy: 54.4\n",
            "epoch: 5\n",
            "batch accuracy: 58.2\n",
            "epoch: 6\n",
            "batch accuracy: 54.2\n",
            "epoch: 7\n",
            "batch accuracy: 54.6\n",
            "epoch: 8\n",
            "batch accuracy: 57.2\n",
            "epoch: 9\n",
            "batch accuracy: 52.2\n",
            "epoch: 10\n",
            "batch accuracy: 51.0\n",
            "epoch: 11\n",
            "batch accuracy: 54.4\n",
            "epoch: 12\n",
            "batch accuracy: 54.0\n",
            "batch: 2\n",
            "epoch: 1\n",
            "batch accuracy: 32.0\n",
            "epoch: 2\n",
            "batch accuracy: 34.8\n",
            "epoch: 3\n",
            "batch accuracy: 31.2\n",
            "epoch: 4\n",
            "batch accuracy: 42.2\n",
            "epoch: 5\n",
            "batch accuracy: 55.2\n",
            "epoch: 6\n",
            "batch accuracy: 58.0\n",
            "epoch: 7\n",
            "batch accuracy: 59.2\n",
            "epoch: 8\n",
            "batch accuracy: 58.0\n",
            "epoch: 9\n",
            "batch accuracy: 58.8\n",
            "epoch: 10\n",
            "batch accuracy: 62.0\n",
            "epoch: 11\n",
            "batch accuracy: 63.0\n",
            "epoch: 12\n",
            "batch accuracy: 63.0\n",
            "epoch: 13\n",
            "batch accuracy: 62.4\n",
            "batch: 3\n",
            "epoch: 1\n",
            "batch accuracy: 56.0\n",
            "epoch: 2\n",
            "batch accuracy: 59.4\n",
            "epoch: 3\n",
            "batch accuracy: 61.6\n",
            "epoch: 4\n",
            "batch accuracy: 62.2\n",
            "epoch: 5\n",
            "batch accuracy: 63.0\n",
            "epoch: 6\n",
            "batch accuracy: 65.4\n",
            "epoch: 7\n",
            "batch accuracy: 67.4\n",
            "epoch: 8\n",
            "batch accuracy: 70.0\n",
            "epoch: 9\n",
            "batch accuracy: 72.0\n",
            "epoch: 10\n",
            "batch accuracy: 72.8\n",
            "epoch: 11\n",
            "batch accuracy: 73.4\n",
            "epoch: 12\n",
            "batch accuracy: 74.2\n",
            "epoch: 13\n",
            "batch accuracy: 78.6\n",
            "epoch: 14\n",
            "batch accuracy: 85.0\n",
            "batch: 4\n",
            "epoch: 1\n",
            "batch accuracy: 63.4\n",
            "epoch: 2\n",
            "batch accuracy: 64.6\n",
            "epoch: 3\n",
            "batch accuracy: 65.2\n",
            "epoch: 4\n",
            "batch accuracy: 65.2\n",
            "epoch: 5\n",
            "batch accuracy: 65.4\n",
            "epoch: 6\n",
            "batch accuracy: 66.8\n",
            "epoch: 7\n",
            "batch accuracy: 69.4\n",
            "epoch: 8\n",
            "batch accuracy: 75.0\n",
            "epoch: 9\n",
            "batch accuracy: 81.2\n",
            "epoch: 10\n",
            "batch accuracy: 87.0\n",
            "epoch: 11\n",
            "batch accuracy: 89.8\n",
            "epoch: 12\n",
            "batch accuracy: 92.0\n",
            "batch: 5\n",
            "epoch: 1\n",
            "batch accuracy: 68.8\n",
            "epoch: 2\n",
            "batch accuracy: 69.4\n",
            "epoch: 3\n",
            "batch accuracy: 69.8\n",
            "epoch: 4\n",
            "batch accuracy: 71.0\n",
            "epoch: 5\n",
            "batch accuracy: 71.6\n",
            "epoch: 6\n",
            "batch accuracy: 73.2\n",
            "epoch: 7\n",
            "batch accuracy: 76.6\n",
            "epoch: 8\n",
            "batch accuracy: 83.6\n",
            "epoch: 9\n",
            "batch accuracy: 91.8\n",
            "batch: 6\n",
            "epoch: 1\n",
            "batch accuracy: 68.6\n",
            "epoch: 2\n",
            "batch accuracy: 70.4\n",
            "epoch: 3\n",
            "batch accuracy: 70.8\n",
            "epoch: 4\n",
            "batch accuracy: 71.0\n",
            "epoch: 5\n",
            "batch accuracy: 72.4\n",
            "epoch: 6\n",
            "batch accuracy: 75.2\n",
            "epoch: 7\n",
            "batch accuracy: 81.4\n",
            "epoch: 8\n",
            "batch accuracy: 87.4\n",
            "epoch: 9\n",
            "batch accuracy: 94.0\n",
            "batch: 7\n",
            "epoch: 1\n",
            "batch accuracy: 68.6\n",
            "epoch: 2\n",
            "batch accuracy: 69.8\n",
            "epoch: 3\n",
            "batch accuracy: 71.2\n",
            "epoch: 4\n",
            "batch accuracy: 71.4\n",
            "epoch: 5\n",
            "batch accuracy: 73.0\n",
            "epoch: 6\n",
            "batch accuracy: 76.6\n",
            "epoch: 7\n",
            "batch accuracy: 83.0\n",
            "epoch: 8\n",
            "batch accuracy: 90.2\n",
            "batch: 8\n",
            "epoch: 1\n",
            "batch accuracy: 76.0\n",
            "epoch: 2\n",
            "batch accuracy: 76.4\n",
            "epoch: 3\n",
            "batch accuracy: 77.8\n",
            "epoch: 4\n",
            "batch accuracy: 78.0\n",
            "epoch: 5\n",
            "batch accuracy: 79.8\n",
            "epoch: 6\n",
            "batch accuracy: 82.4\n",
            "epoch: 7\n",
            "batch accuracy: 87.2\n",
            "epoch: 8\n",
            "batch accuracy: 94.0\n",
            "batch: 9\n",
            "epoch: 1\n",
            "batch accuracy: 75.4\n",
            "epoch: 2\n",
            "batch accuracy: 75.8\n",
            "epoch: 3\n",
            "batch accuracy: 77.4\n",
            "epoch: 4\n",
            "batch accuracy: 77.8\n",
            "epoch: 5\n",
            "batch accuracy: 79.8\n",
            "epoch: 6\n",
            "batch accuracy: 85.4\n",
            "epoch: 7\n",
            "batch accuracy: 92.4\n",
            "batch: 10\n",
            "epoch: 1\n",
            "batch accuracy: 71.6\n",
            "epoch: 2\n",
            "batch accuracy: 72.0\n",
            "epoch: 3\n",
            "batch accuracy: 72.8\n",
            "epoch: 4\n",
            "batch accuracy: 74.4\n",
            "epoch: 5\n",
            "batch accuracy: 80.6\n",
            "epoch: 6\n",
            "batch accuracy: 88.0\n",
            "epoch: 7\n",
            "batch accuracy: 93.6\n",
            "batch: 11\n",
            "epoch: 1\n",
            "batch accuracy: 70.2\n",
            "epoch: 2\n",
            "batch accuracy: 70.6\n",
            "epoch: 3\n",
            "batch accuracy: 71.4\n",
            "epoch: 4\n",
            "batch accuracy: 74.8\n",
            "epoch: 5\n",
            "batch accuracy: 81.2\n",
            "epoch: 6\n",
            "batch accuracy: 90.6\n",
            "batch: 12\n",
            "epoch: 1\n",
            "batch accuracy: 73.0\n",
            "epoch: 2\n",
            "batch accuracy: 74.0\n",
            "epoch: 3\n",
            "batch accuracy: 75.8\n",
            "epoch: 4\n",
            "batch accuracy: 79.6\n",
            "epoch: 5\n",
            "batch accuracy: 86.2\n",
            "epoch: 6\n",
            "batch accuracy: 93.0\n",
            "batch: 13\n",
            "epoch: 1\n",
            "batch accuracy: 78.8\n",
            "epoch: 2\n",
            "batch accuracy: 79.0\n",
            "epoch: 3\n",
            "batch accuracy: 80.0\n",
            "epoch: 4\n",
            "batch accuracy: 83.6\n",
            "epoch: 5\n",
            "batch accuracy: 91.0\n",
            "batch: 14\n",
            "epoch: 1\n",
            "batch accuracy: 77.6\n",
            "epoch: 2\n",
            "batch accuracy: 77.8\n",
            "epoch: 3\n",
            "batch accuracy: 78.0\n",
            "epoch: 4\n",
            "batch accuracy: 80.4\n",
            "epoch: 5\n",
            "batch accuracy: 88.4\n",
            "epoch: 6\n",
            "batch accuracy: 94.4\n",
            "batch: 15\n",
            "epoch: 1\n",
            "batch accuracy: 79.2\n",
            "epoch: 2\n",
            "batch accuracy: 80.0\n",
            "epoch: 3\n",
            "batch accuracy: 80.2\n",
            "epoch: 4\n",
            "batch accuracy: 81.4\n",
            "epoch: 5\n",
            "batch accuracy: 87.0\n",
            "epoch: 6\n",
            "batch accuracy: 94.4\n",
            "batch: 16\n",
            "epoch: 1\n",
            "batch accuracy: 78.2\n",
            "epoch: 2\n",
            "batch accuracy: 78.2\n",
            "epoch: 3\n",
            "batch accuracy: 79.4\n",
            "epoch: 4\n",
            "batch accuracy: 81.0\n",
            "epoch: 5\n",
            "batch accuracy: 88.4\n",
            "epoch: 6\n",
            "batch accuracy: 95.8\n",
            "batch: 17\n",
            "epoch: 1\n",
            "batch accuracy: 85.0\n",
            "epoch: 2\n",
            "batch accuracy: 85.4\n",
            "epoch: 3\n",
            "batch accuracy: 85.8\n",
            "epoch: 4\n",
            "batch accuracy: 87.6\n",
            "epoch: 5\n",
            "batch accuracy: 90.8\n",
            "batch: 18\n",
            "epoch: 1\n",
            "batch accuracy: 78.8\n",
            "epoch: 2\n",
            "batch accuracy: 79.2\n",
            "epoch: 3\n",
            "batch accuracy: 79.4\n",
            "epoch: 4\n",
            "batch accuracy: 83.4\n",
            "epoch: 5\n",
            "batch accuracy: 90.8\n",
            "batch: 19\n",
            "epoch: 1\n",
            "batch accuracy: 83.6\n",
            "epoch: 2\n",
            "batch accuracy: 83.6\n",
            "epoch: 3\n",
            "batch accuracy: 84.2\n",
            "epoch: 4\n",
            "batch accuracy: 88.0\n",
            "epoch: 5\n",
            "batch accuracy: 92.8\n",
            "batch: 20\n",
            "epoch: 1\n",
            "batch accuracy: 88.6\n",
            "epoch: 2\n",
            "batch accuracy: 89.2\n",
            "epoch: 3\n",
            "batch accuracy: 89.4\n",
            "epoch: 4\n",
            "batch accuracy: 91.6\n",
            "batch: 21\n",
            "epoch: 1\n",
            "batch accuracy: 87.2\n",
            "epoch: 2\n",
            "batch accuracy: 87.2\n",
            "epoch: 3\n",
            "batch accuracy: 88.0\n",
            "epoch: 4\n",
            "batch accuracy: 90.6\n",
            "batch: 22\n",
            "epoch: 1\n",
            "batch accuracy: 90.47619047619048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(model, sentence, num_dict, word_dict):\n",
        "  '''\n",
        "  '''\n",
        "  filtered = re.sub(r\"[;:,]\", r\"\", sentence)\n",
        "  filtered = re.sub(r\"\\.\", r\" eos\", filtered)\n",
        "  filtered = re.sub(r\"\\?\", r\" eosq\", filtered)\n",
        "  filtered = re.sub(r\"!\", r\"\", filtered)\n",
        "  filtered = re.sub(r\"-\", r\"\", filtered)\n",
        "  filtered = re.sub(r\"\\d\", r\"\", filtered)\n",
        "  filtered = re.sub(r\"\\\\\", r\"\", filtered)\n",
        "  filtered = re.sub(r\"\\\"\", r\"\", filtered)\n",
        "  filtered = re.sub(r\"\\s+\", r\" \", filtered)\n",
        "  filtered = filtered.lower()\n",
        "  token_list = re.split(r\"\\s\", filtered)\n",
        "  token_list = token_list[-3:]\n",
        "  tensor = []\n",
        "  for token in token_list:\n",
        "    d = word_dict[token]\n",
        "    t = torch.zeros((len(num_dict.keys()),))\n",
        "    t[d] = 1\n",
        "    tensor.append(t)\n",
        "  tensor = torch.vstack(tuple(tensor))\n",
        "  tensor = torch.reshape(tensor, (3, 1, len(num_dict.keys())))\n",
        "  output = model.forward(tensor)\n",
        "  output = output[0]\n",
        "  prediction = torch.argmax(output).item()\n",
        "  return num_dict[prediction]"
      ],
      "metadata": {
        "id": "GclQazZezBur"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_list[18])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZ3miNlf56lb",
        "outputId": "af142ace-f609-4e00-bbe2-f4f7f16fbfd5"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sos once upon a timeof all the good days in the year on christmas eveold scrooge sat busy in his countinghouse eos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(rnn, \"once upon a timeof all the \", num_dict, word_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lkP463n8VWh",
        "outputId": "ee6f1346-e113-44c3-9871-19e343ddd5cd"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ceiling\n",
            "and\n",
            "known\n",
            "of\n",
            "the\n",
            "goose\n",
            "and\n",
            "known\n",
            "of\n",
            "the\n",
            "goose\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, string, num_dict, word_dict):\n",
        "  '''\n",
        "  '''\n",
        "  token = predict_next_word(model, string, num_dict, word_dict)\n",
        "  n = 0\n",
        "  while(token != 'eos' and n < 10):\n",
        "    print(token)\n",
        "    token = predict_next_word(model, f\"{string} {token} \", num_dict, word_dict)\n",
        "    n+=1\n",
        "  print(token)"
      ],
      "metadata": {
        "id": "KKAvpUW5X_c2"
      },
      "execution_count": 35,
      "outputs": []
    }
  ]
}
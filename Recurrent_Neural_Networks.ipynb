{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1xtk0GlgjVNWZsHwG8-vcmgWgj3my3lv4",
      "authorship_tag": "ABX9TyOYBEpUUXBabor3AYgYS8qk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zelalemamera-stonybrook/projects-sandbox/blob/main/Recurrent_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8cqCkctcC7n",
        "outputId": "d36d35d8-228a-4894-c273-23335ec86033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchcodec\n",
            "  Downloading torchcodec-0.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Downloading torchcodec-0.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (2.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchcodec\n",
            "Successfully installed torchcodec-0.9.1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "!pip install torchcodec\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pack_sequence"
      ],
      "metadata": {
        "id": "dPn9p8TdcM-V"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randint(0, 100, size=(5,))\n",
        "b = torch.randint(0,100,size=(10,))\n",
        "c = torch.randint(0,100, size=(3,))\n",
        "d = torch.randint(0,100, size=(7,))\n",
        "e = torch.randint(0, 100, (8,))\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "print(d)\n",
        "print(e)\n",
        "packed = pack_sequence([a,b,c,d,e], enforce_sorted=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2YIJUvJdHMf",
        "outputId": "6d882a36-1838-4e67-98f9-362d3790555a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([24, 80, 91, 43, 52])\n",
            "tensor([26, 87, 96, 26,  9, 58, 71,  7, 15, 26])\n",
            "tensor([98, 38,  4])\n",
            "tensor([31,  8, 31, 54, 41, 12, 85])\n",
            "tensor([27, 46, 12, 50, 54, 42, 16, 26])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "packed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7uSL2_PdPHZ",
        "outputId": "808fd9b4-8983-4de7-a5a5-6dba95c41b25"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PackedSequence(data=tensor([26, 27, 31, 24, 98, 87, 46,  8, 80, 38, 96, 12, 31, 91,  4, 26, 50, 54,\n",
              "        43,  9, 54, 41, 52, 58, 42, 12, 71, 16, 85,  7, 26, 15, 26]), batch_sizes=tensor([5, 5, 5, 4, 4, 3, 3, 2, 1, 1]), sorted_indices=tensor([1, 4, 3, 0, 2]), unsorted_indices=tensor([3, 0, 4, 2, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand((1,2,3))\n",
        "b = torch.rand([1,2,4])\n",
        "print(a, f\"\\n{b}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RbM7nV0kwGb",
        "outputId": "2cf17771-eef5-498d-b140-1db5238470f1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.0598, 0.4744, 0.1710],\n",
            "         [0.7765, 0.6359, 0.1096]]]) \n",
            "tensor([[[0.9639, 0.4345, 0.5113, 0.4837],\n",
            "         [0.5148, 0.5659, 0.7505, 0.9326]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([3.0, 2, 1], requires_grad=True)\n",
        "b = torch.tensor([5.0, 6, 7], requires_grad=True)\n",
        "print(a)\n",
        "print(b)\n",
        "c = (a ** 2) @ b\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mekycLtlQDC",
        "outputId": "89bfff49-1249-4e57-c209-4b4e04c56c68"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 2., 1.], requires_grad=True)\n",
            "tensor([5., 6., 7.], requires_grad=True)\n",
            "tensor(76., grad_fn=<DotBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dist = c ** 2\n",
        "dist2 = 2 + dist\n",
        "dist3 = dist2 ** 2"
      ],
      "metadata": {
        "id": "FZhxf2bIwHq2"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.autograd.backward(c)"
      ],
      "metadata": {
        "id": "-UIUJTcS-kaZ"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dist3.grad, dist3.grad_fn.next_functions, dist2.grad_fn.next_functions, f\"\\n{dist.grad_fn.next_functions}\", c.grad_fn.next_functions,\n",
        "      f\"\\n{a.grad_fn}\", b.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1V1493MxWTh",
        "outputId": "2280a51e-ae64-4ead-814e-a3096d032525"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None ((<AddBackward0 object at 0x7c5975f11750>, 0),) ((<PowBackward0 object at 0x7c5975b1aa10>, 0), (None, 0)) \n",
            "((<DotBackward0 object at 0x7c5975f1ab30>, 0),) ((<AccumulateGrad object at 0x7c5975b45000>, 0), (<AccumulateGrad object at 0x7c5975b45360>, 0)) \n",
            "None None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2088928086.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information. (Triggered internally at /pytorch/build/aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(dist3.grad, dist3.grad_fn.next_functions, dist2.grad_fn.next_functions, f\"\\n{dist.grad_fn.next_functions}\", c.grad_fn.next_functions,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "waveform, samplerate = torchaudio.load('/content/drive/MyDrive/Train_audio/audio1.wav')"
      ],
      "metadata": {
        "id": "Fi8x0kIoGG_n"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.RNNBase):\n",
        "\n",
        "  def _init_(self, input_size, hidden_size, output_size):\n",
        "    super().__init__()\n",
        "    self.output_matrix = torch.rand((self.output_size, self.hidden_size))\n",
        "    self.softmax = nn.Softmax(dim=0)\n",
        "    self.output_size = output_size\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.hidden_layer = nn.RNNCell(input_size, hidden_size)\n",
        "\n",
        "  def forward(self, input_sequence):\n",
        "    hidden_list = []\n",
        "    h0 = torch.zeros((self.hidden_size))\n",
        "    for input in input_sequence:\n",
        "      h0 = self.hidden_layer(input, h0)\n",
        "      hidden_list.append(h0)\n",
        "    output_hidden_layer = hidden_list[-1]\n",
        "    output = self.softmax(self.output_matrix @ output_hidden_layer)\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "3z5bMnSNGOGO"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, input_data, target_data):\n",
        "  '''\n",
        "  '''\n",
        ""
      ],
      "metadata": {
        "id": "EY8rv9T_JtOW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
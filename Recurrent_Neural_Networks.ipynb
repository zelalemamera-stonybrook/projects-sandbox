{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1xtk0GlgjVNWZsHwG8-vcmgWgj3my3lv4",
      "authorship_tag": "ABX9TyMfkBc9pllQ9wrqY/TI4E1l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zelalemamera-stonybrook/projects-sandbox/blob/main/Recurrent_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t8cqCkctcC7n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/charles_dickens_christmas_carol.txt', 'r') as f:\n",
        "  scroodge_book = f.read()"
      ],
      "metadata": {
        "id": "egNJtNmlO0e7"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_sentences(sentence_list):\n",
        "  '''\n",
        "  Add SOS - start of sentence and EOS end of sentence markers.\n",
        "  Add EOSq for end of sentence question\n",
        "  replace ; : with EOS\n",
        "  replace ! with ,\n",
        "  remove - i.e. treat every compound word as one unit\n",
        "  remove all numbers\n",
        "  remove \\\n",
        "  remove \"\n",
        "  '''\n",
        "  cleaned_sentence_list = []\n",
        "  for sentence in sentence_list:\n",
        "    filtered = re.sub(r\"[;:,]\", r\"\", sentence)\n",
        "    filtered = re.sub(r\"\\.\", r\" eos\", filtered)\n",
        "    filtered = re.sub(r\"\\?\", r\" eosq\", filtered)\n",
        "    filtered = re.sub(r\"!\", r\"\", filtered)\n",
        "    filtered = re.sub(r\"-\", r\"\", filtered)\n",
        "    filtered = re.sub(r\"\\d\", r\"\", filtered)\n",
        "    filtered = re.sub(r\"\\\\\", r\"\", filtered)\n",
        "    filtered = re.sub(r\"\\\"\", r\"\", filtered)\n",
        "    filtered = re.sub(r\"\\s+\", r\" \", filtered)\n",
        "    filtered = filtered.lower()\n",
        "    cleaned_sentence_list.append(f\"sos {filtered}\")\n",
        "  return cleaned_sentence_list\n",
        "\n"
      ],
      "metadata": {
        "id": "8iXO0PcuHFu0"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_book_and_tokenize_sentences(book):\n",
        "  '''\n",
        "  '''\n",
        "  list_of_undesirables = [\"STAVE I:  MARLEY'S GHOST\", \"STAVE II:  THE FIRST OF THE THREE SPIRITS\", \"STAVE III:  THE SECOND OF THE THREE SPIRITS\",\n",
        "                   \"A CHRISTMAS CAROL\", \"Stave IV:  The Last of the Spirits\", \"Stave V:  The End of It\"]\n",
        "  for string in list_of_undesirables:\n",
        "    book = re.sub(string, r\"\", book)\n",
        "  book = re.sub(\"\\n\", r\" \", book)\n",
        "  sentence_list = [\". marley was dead.\"]\n",
        "  appendage = re.findall(r\"\\..*?\\.\", book)\n",
        "  for appendend in appendage:\n",
        "    sentence_list.append(appendend)\n",
        "  for i, sentence in enumerate(sentence_list):\n",
        "    sentence_list[i] = sentence[1:].strip()\n",
        "  cleaned_sentence_list = clean_sentences(sentence_list)\n",
        "  return cleaned_sentence_list\n",
        ""
      ],
      "metadata": {
        "id": "y8d3UOKLTxSO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_list = clean_book_and_tokenize_sentences(scroodge_book)"
      ],
      "metadata": {
        "id": "Ohx067ANXce-"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = [1,2,3, 4, 5, 6]\n",
        "b = [2,3,4,5,6]\n",
        "c = [3,4,5,6]\n",
        "d = zip(a,b,c)\n",
        "for i in d:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-AcdAsWjaSK",
        "outputId": "9ad232b7-d36f-41e8-bc12-210ca96d4645"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 2, 3)\n",
            "(2, 3, 4)\n",
            "(3, 4, 5)\n",
            "(4, 5, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_list[-20:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXS-6V4dYV7C",
        "outputId": "87975a95-af1f-4ea5-a4d3-92ae97aa9db7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sos your uncle scrooge eos',\n",
              " \"sos will you let me in fred eosq let him in it is a mercy he didn't shake his arm off eos\",\n",
              " 'sos nothing could be heartier eos',\n",
              " 'sos so did topper when he came eos',\n",
              " 'sos so did every one when they came eos',\n",
              " 'sos oh he was early there eos',\n",
              " 'sos and he did it yes he did the clock struck nine eos',\n",
              " 'sos a quarter past eos',\n",
              " 'sos he was full eighteen minutes and a half behind his time eos',\n",
              " 'sos his hat was off before he opened the door his comforter too eos',\n",
              " 'sos hallo growled scrooge in his accustomed voice as near as he could feign it eos',\n",
              " 'sos i am behind my time eos',\n",
              " 'sos yes eos',\n",
              " 'sos step this way sir if you please eos',\n",
              " 'sos it shall not be repeated eos',\n",
              " \"sos  now i'll tell you what my friend said scrooge i am not going to stand this sort of thing any longer eos\",\n",
              " 'sos he had a momentary idea of knocking scrooge down with it holding him and calling to the people in the court for help and a straitwaistcoat eos',\n",
              " \"sos a merrier christmas bob my good fellow than i have given you for many a year i'll raise your salary and endeavour to assist your struggling family and we will discuss your affairs this very afternoon over a christmas bowl of smoking bishop bob make up the fires and buy another coalscuttle before you dot another i bob cratchit scrooge was better than his word eos\",\n",
              " 'sos he became as good a friend as good a master and as good a man as the good old city knew or any other good old city town or borough in the good old world eos',\n",
              " 'sos his own heart laughed and that was quite enough for him eos']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_one_hot_mapping(sentence_list):\n",
        "  '''\n",
        "  '''\n",
        "  words_to_int = {}\n",
        "  int_to_words = {}\n",
        "  size = 0\n",
        "  for sentence in sentence_list:\n",
        "    words = re.split(r\"\\s\", sentence)\n",
        "    for word in words:\n",
        "      if word in words_to_int.keys():\n",
        "        continue\n",
        "      else:\n",
        "        words_to_int[word] = size\n",
        "        int_to_words[size] = word\n",
        "        size += 1\n",
        "  return (int_to_words, words_to_int)\n"
      ],
      "metadata": {
        "id": "n2YIJUvJdHMf"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_to_num(sentence_list):\n",
        "  '''\n",
        "  '''\n",
        "  num_dict, word_dict = generate_one_hot_mapping(sentence_list)\n",
        "  translated_sequences = []\n",
        "  for sentence in sentence_list:\n",
        "    words = re.split(r\"\\s\", sentence)\n",
        "    sequence = []\n",
        "    for word in words:\n",
        "      try:\n",
        "        sequence.append(word_dict[word])\n",
        "      except Exception:\n",
        "        continue\n",
        "    translated_sequences.append(sequence)\n",
        "  return translated_sequences, num_dict, word_dict"
      ],
      "metadata": {
        "id": "4mekycLtlQDC"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_training_data(sentence_list):\n",
        "  '''\n",
        "  '''\n",
        "  tensor_list = []\n",
        "  string_sequences, num_dict, word_dict = translate_to_num(sentence_list)\n",
        "  word_dimension = len(num_dict.keys())\n",
        "  for sentence in string_sequences:\n",
        "    zipped = zip(sentence, sentence[1:], sentence[2:])\n",
        "    for tup in zipped:\n",
        "      if tup in tensor_list:\n",
        "        continue\n",
        "      tensor_list.append(tup)\n",
        "  matrix_list = []\n",
        "  for tup in tensor_list:\n",
        "    tensor = torch.zeros((3, word_dimension))\n",
        "    for i in range(len(tup)):\n",
        "      tensor[i,tup[i]] = 1\n",
        "    matrix_list.append(tensor)\n",
        "  return matrix_list, num_dict, word_dict"
      ],
      "metadata": {
        "id": "X1V1493MxWTh"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string_matrices, num_dict, word_dict = generate_training_data(sentence_list)"
      ],
      "metadata": {
        "id": "FZhxf2bIwHq2"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(string_matrices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8fl13F0tgL-",
        "outputId": "3044b659-d287-43d5-bde9-2a72c0dd29ef"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14247"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_strings(string_matrices, num_dict):\n",
        "  '''\n",
        "  '''\n",
        "  string_list = []\n",
        "  for matrix in string_matrices:\n",
        "    word1 = num_dict[torch.argmax(matrix[0,:]).item()]\n",
        "    word2 = num_dict[torch.argmax(matrix[1,:]).item()]\n",
        "    word3 = num_dict[torch.argmax(matrix[2,:]).item()]\n",
        "    string_list.append((word1,word2,word3))\n",
        "  return string_list"
      ],
      "metadata": {
        "id": "1mFVLLCpGiLQ"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string_list = to_strings(string_matrices, num_dict)"
      ],
      "metadata": {
        "id": "6fZJeFlRHJtx"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string_list[-30:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjKO-iXrHg_3",
        "outputId": "70286eef-c296-4d42-9b35-83f188ab709f"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('as', 'the', 'good'),\n",
              " ('the', 'good', 'old'),\n",
              " ('good', 'old', 'city'),\n",
              " ('old', 'city', 'knew'),\n",
              " ('city', 'knew', 'or'),\n",
              " ('knew', 'or', 'any'),\n",
              " ('or', 'any', 'other'),\n",
              " ('any', 'other', 'good'),\n",
              " ('other', 'good', 'old'),\n",
              " ('good', 'old', 'city'),\n",
              " ('old', 'city', 'town'),\n",
              " ('city', 'town', 'or'),\n",
              " ('town', 'or', 'borough'),\n",
              " ('or', 'borough', 'in'),\n",
              " ('borough', 'in', 'the'),\n",
              " ('in', 'the', 'good'),\n",
              " ('the', 'good', 'old'),\n",
              " ('good', 'old', 'world'),\n",
              " ('old', 'world', 'eos'),\n",
              " ('sos', 'his', 'own'),\n",
              " ('his', 'own', 'heart'),\n",
              " ('own', 'heart', 'laughed'),\n",
              " ('heart', 'laughed', 'and'),\n",
              " ('laughed', 'and', 'that'),\n",
              " ('and', 'that', 'was'),\n",
              " ('that', 'was', 'quite'),\n",
              " ('was', 'quite', 'enough'),\n",
              " ('quite', 'enough', 'for'),\n",
              " ('enough', 'for', 'him'),\n",
              " ('for', 'him', 'eos')]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super().__init__()\n",
        "    output_matrix = torch.rand((output_size, hidden_size), requires_grad=True)\n",
        "    self.output_layer = nn.Parameter(output_matrix, requires_grad=True)\n",
        "    self.output_layer_bias = nn.Parameter(torch.rand((output_size)), requires_grad=True)\n",
        "    self.loss = nn.CrossEntropyLoss()\n",
        "    self.output_size = output_size\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.hidden_layer = nn.RNNCell(input_size, hidden_size)\n",
        "\n",
        "  def forward(self, input_sequence):\n",
        "    hidden_list = []\n",
        "    h0 = torch.zeros((self.hidden_size))\n",
        "    for input in input_sequence:\n",
        "      h0 = self.hidden_layer(input, h0)\n",
        "      hidden_list.append(h0)\n",
        "    output_list = []\n",
        "    for hidden in hidden_list:\n",
        "      output = (self.output_layer @ hidden) + self.output_layer_bias\n",
        "      output_list.append(output)\n",
        "    return torch.vstack(tuple(output_list))\n"
      ],
      "metadata": {
        "id": "3z5bMnSNGOGO"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, list_of_sequences, epochs):\n",
        "  '''\n",
        "  '''\n",
        "  model.train()\n",
        "  optim = torch.optim.Adam(model.parameters())\n",
        "  for i in range(epochs):\n",
        "    print(f\"epoch: {i}\")\n",
        "    n = torch.randint(0,len(list_of_sequences) - 1, (1,))\n",
        "    sequence = list_of_sequences[n]\n",
        "    length = sequence.shape[0]\n",
        "    avg_loss = float('inf')\n",
        "    maximum_iterations = 1\n",
        "    while avg_loss > .09 and maximum_iterations < 50:\n",
        "      optim.zero_grad()\n",
        "      output = model.forward(sequence[: length - 1, :])\n",
        "      loss = model.loss(output, sequence[1:, :])\n",
        "      loss.backward()\n",
        "      optim.step()\n",
        "      avg_loss = loss.item() / length\n",
        "      maximum_iterations+=1\n",
        "      #print(f\"accuracy: {model_accuracy(model, sequence[:length - 1, :], sequence[1:, :])}\")\n",
        "    print(f\"loss: {loss.item()}\", f\"\\nsentence length: {length}\", f\"\\naverage loss: {avg_loss}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "EY8rv9T_JtOW"
      },
      "execution_count": 273,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_accuracy(model, input_data, target_data):\n",
        "  '''\n",
        "  '''\n",
        "  model.eval()\n",
        "  predictions = torch.argmax(model.forward(input_data), dim=1)\n",
        "  score = 100 * (torch.sum(torch.eq(predictions, target_data))).item() / len(target_data)\n",
        "  return score\n"
      ],
      "metadata": {
        "id": "hqFGBjLY8Xkz"
      },
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 2590\n",
        "hidden_size = 1000\n",
        "output_size = 2590\n",
        "total_params = hidden_size * input_size + hidden_size * hidden_size + output_size * hidden_size + hidden_size + hidden_size + output_size\n",
        "print(f\"total parameters: {total_params}\", f\"\\napproximate size: {float((total_params * 32) / float(10**9))} giga bytes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLL_YHhcRXot",
        "outputId": "6dc59a28-b113-4662-b4eb-febd129da953"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total parameters: 6184590 \n",
            "approximate size: 0.19790688 giga bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn = RNN(input_size, hidden_size, output_size)"
      ],
      "metadata": {
        "id": "G4D48BepL2ao"
      },
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(rnn, training_list, 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhu27TaIT54x",
        "outputId": "731e5cdb-bf0c-4b11-bcf0-5449367c5e26"
      },
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\n",
            "loss: 4.511712074279785 \n",
            "sentence length: 63 \n",
            "average loss: 0.0716144773695204\n",
            "epoch: 1\n",
            "loss: 0.4323976933956146 \n",
            "sentence length: 5 \n",
            "average loss: 0.08647953867912292\n",
            "epoch: 2\n",
            "loss: 1.0739836692810059 \n",
            "sentence length: 12 \n",
            "average loss: 0.08949863910675049\n",
            "epoch: 3\n",
            "loss: 4.5642194747924805 \n",
            "sentence length: 58 \n",
            "average loss: 0.07869343922056\n",
            "epoch: 4\n",
            "loss: 2.9248833656311035 \n",
            "sentence length: 45 \n",
            "average loss: 0.06499740812513563\n",
            "epoch: 5\n",
            "loss: 0.8953339457511902 \n",
            "sentence length: 10 \n",
            "average loss: 0.08953339457511902\n",
            "epoch: 6\n",
            "loss: 0.7896752953529358 \n",
            "sentence length: 9 \n",
            "average loss: 0.08774169948365954\n",
            "epoch: 7\n",
            "loss: 1.3137587308883667 \n",
            "sentence length: 15 \n",
            "average loss: 0.08758391539255778\n",
            "epoch: 8\n",
            "loss: 3.382600784301758 \n",
            "sentence length: 39 \n",
            "average loss: 0.08673335344363482\n",
            "epoch: 9\n",
            "loss: 0.352754682302475 \n",
            "sentence length: 4 \n",
            "average loss: 0.08818867057561874\n",
            "epoch: 10\n",
            "loss: 0.7894884943962097 \n",
            "sentence length: 9 \n",
            "average loss: 0.08772094382180108\n",
            "epoch: 11\n",
            "loss: 2.4836387634277344 \n",
            "sentence length: 41 \n",
            "average loss: 0.060576555205554494\n",
            "epoch: 12\n",
            "loss: 1.9562455415725708 \n",
            "sentence length: 23 \n",
            "average loss: 0.08505415398141612\n",
            "epoch: 13\n",
            "loss: 0.8040034174919128 \n",
            "sentence length: 10 \n",
            "average loss: 0.08040034174919128\n",
            "epoch: 14\n",
            "loss: 1.6029908657073975 \n",
            "sentence length: 18 \n",
            "average loss: 0.08905504809485541\n",
            "epoch: 15\n",
            "loss: 0.4307870864868164 \n",
            "sentence length: 5 \n",
            "average loss: 0.08615741729736329\n",
            "epoch: 16\n",
            "loss: 8.15021800994873 \n",
            "sentence length: 91 \n",
            "average loss: 0.08956283527416187\n",
            "epoch: 17\n",
            "loss: 1.1478544473648071 \n",
            "sentence length: 13 \n",
            "average loss: 0.088296495951139\n",
            "epoch: 18\n",
            "loss: 5.67362642288208 \n",
            "sentence length: 66 \n",
            "average loss: 0.08596403671033455\n",
            "epoch: 19\n",
            "loss: 0.7084866166114807 \n",
            "sentence length: 8 \n",
            "average loss: 0.08856082707643509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(model, sentence):\n",
        "  '''\n",
        "  '''\n",
        "  tensor = transform_sentence(sentence)\n",
        "  output = model.forward(tensor)\n",
        "  output_list = []\n",
        "  for tensor in output:\n",
        "    integer = torch.argmax(tensor)\n",
        "    output_list.append(map_int[integer.item()])\n",
        "  return output_list"
      ],
      "metadata": {
        "id": "GclQazZezBur"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_sentence(sentence):\n",
        "  '''\n",
        "  '''\n",
        "  filtered = f\"SOS {sentence.strip()}\"\n",
        "  filtered = re.sub(r\"[;:,]\", r\" ,\", filtered)\n",
        "  filtered = re.sub(r\"\\.\", r\"\", filtered)\n",
        "  filtered = re.sub(r\"\\?\", r\"\", filtered)\n",
        "  filtered = re.sub(r\"!\", r\",\", filtered)\n",
        "  filtered = re.sub(r\"-\", r\"\", filtered)\n",
        "  filtered = re.sub(r\"\\d\", r\"\", filtered)\n",
        "  filtered = re.sub(r\"\\\\\", r\"\", filtered)\n",
        "  filtered = re.sub(r\"\\\"\", r\"\", filtered)\n",
        "  print(filtered)\n",
        "  transformed = translate_to_num([filtered], map_words)\n",
        "  print(transformed)\n",
        "  transformed_tensor = generate_training_data(transformed, vocab_size)[0]\n",
        "  print(transformed_tensor)\n",
        "  return transformed_tensor\n"
      ],
      "metadata": {
        "id": "aczUsLSI1ifs"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_next_word(rnn, \"Marley was dead, of that there was no reflected, but where did he\")[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZ3miNlf56lb",
        "outputId": "d69a6b97-9219-4d8c-96a9-ebab0b8fa48c"
      },
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SOS Marley was dead , of that there was no reflected , but where did he\n",
            "[[1, 13, 14, 16, 25, 33, 8, 91, 14, 4, 1974, 25, 68, 621, 453, 49]]\n",
            "tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "EOS\n"
          ]
        }
      ]
    }
  ]
}